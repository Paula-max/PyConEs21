# Psicología Social y Machine Learning: un futuro ético

siglo XVII, América: Se calcula que 60 millones de personas, principalmente de África, fueron secuestradas y esclavizadas.

1791, Francia: Olympe de Gouges escribía La Declaración de los Derechos de la Mujer y de la Ciudadana para reclamar los mismos derechos para mujeres que para hombres. Fue gillotinada en 1793.

1955, Montgomery (Alabama, Estados Unidos): Rosa Parks, mujer afroamericana, es detenida por no ceder su asiento a un hombre blanco.

2016, España: Las personas con discapacidad auditiva presentaban una tasa de desempleo del 55,4%.

2020, Mar Mediterráneo: Más de 1700 personas han perdido la vida intentando cruzar el Mediterráneo, casi 600 en la ruta migratoria a Canarias.

2021, el Mundo: Los actos sexuales consensuales entre personas adultas del mismo sexo siguen siendo criminalizados en casi 70 países.

Los sesgos, la discriminación y desigualdad son parte de nuestro ADN como especie. Ahora, en la era de la tecnología y la automatización se nos presenta un nuevo escenario donde poder expresar estos genes. 

<!-- sesgos y discriminación -->
Quizás las explicaciones psicosociales detras de los sesgos en los modelos de Machine Learning no disten mucho de los que hay en los recién redactados, pero el escenario agrava, sin ninguna duda, las consecuencias. Pensemos, por ejemplo, en cuánto tarda en aprender un programa y cuánto una persona. El último algoritmo de clasificación de textos que hemos desarrollado tarda 7 segundos en entrenar, por nuestra parte, hemos estado casi 25 años dentro del sistema educativo. Pensemos también en cuánto tiempo del día pasamos sin entrar en contacto con aparatos tecnológicos que registren nuestro comportamiento. O también, en el número de empresas y organismos públicos que a día de hoy ponen sus decisiones en modelos que, en ocasiones, no comprenden bien. 

<!-- desigualdad, acceso a estas herramientas -->
Otro frente, es el acceso a dichos sistemas. El desarrollo de algunos sistemas de Inteligencia Artificial cuesta millones de euros, que junto a la infraestructura y costos de uso, los limita a unos pocos usuarios. A medida que el uso de sistemas de Inteligencia Artificial se incrementa en nuestro día a día, la desigualdad entre las personas que pueden utilizar estos sistemas y las que no se incrementará, llegando a producir una ventaja competitiva, posiblemente, insalvable.

<!-- primera y segunda, diversificación y educación. --> 
Frente a estas situación la primera de las soluciones pasa por diversificar el poder, concienciar a la gente sobre el uso y problematicas de la Inteligencia Artificial, y permitir y favorecer que los equipos que desarrollan los algoritmos estén formados por personas minorizadas y diversas. En nuestro poder tenemos las herramientas para combatir los sesgos y sus consecuencias negativas. 

<!-- ML -->
Por otro lado, las personas que actualmente trabajamos desarrollando estos sistemas tenemos que concienciarnos de que estos sistemas no se reducen a un número (elegir: accuracy, tasa de error..), y que detrás de esos números hay personas que se veran influenciadas.

¿Y de donde vienen los sesgos de esos sistemas? Estos sesgos se encuentran principalmente en los datos con los que son entrenados estos sistemas. Además, también hay otra fuente de sesgos, que nosotros como desarrolladores introducimos con nuestras decisiones en el modelado (sesgos inductivos). Aunque los sesgos inductivos son necesarios en el modelado, las decisiones que tomemos pueden llevar a reducir o incrementar los sesgos presentes en los datos.

Ante los sesgos en los datos, nos podríamos plantear si deberiamos tratar de mitigar estos sesgos en nuestros modelos, o no hacer nada, y esperar que los sesgos se mitiguen en los datos. Este ultimo enfoque, si bien mitigaria los sesgos en el modelo, pueden ser procesos que duren decadas, sobre todo si estos están arraigados en la sociedad. Además, corremos el riesgo de que los modelos perpetuen estos sesgos (__feedback loops__). Por otra parte, los beneficios de tratar los sesgos de los datos en el modelado son muchos, y van desde sistemas mas justos hasta el cumplimiento de posibles futuras regulaciones (EU Commission, 2020). 

- Ténicas de Explanaible Artificial Intelligence (XAI): Son un grupo de técnicas que nos permiten comprender, generalmente de forma parcial, el funcionamiento de un sistema de Inteligencia Artificial. A través de ese entendimiento podemos, por ejemplo, mejorar los modelos y diagnosticar posibles sesgos.
- Técnicas de Fairness Artificial Intelligence: Junto a las técnicas de XAI nos permitirán diagnosticar y aplicar medidas para disminuir los sesgos.

Después de hacernos más conscientes del problema social al que nos enfrentamos y de las consecuencias negativas que tienen sobre las vidad cotidianas de las personas, ver estas herremientas a través de su aplicación en casos de estudio es el escalón necesario para pasar a la acción y conseguir un presente y futuro mucho más etico y justo.


## Referencias
EU Commission. (2020). White Paper on Artificial Intelligence—A European Approach to Excellence and Trust. COM (2020), 65.

<!-- 
TODO: Cambiar Machine Learning por Artificial Intelligence? 

-->